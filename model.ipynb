{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        v        vw       o       c       h       l  \\\n",
      "timestamp                                                             \n",
      "2023-01-03 09:00:00  2711  149.3257  150.70  148.95  151.00  148.17   \n",
      "2023-01-03 09:02:00   388  148.8909  148.94  148.94  148.94  148.94   \n",
      "2023-01-03 09:03:00   609  148.8008  148.85  148.85  148.85  148.85   \n",
      "2023-01-03 09:04:00  1155  148.8968  148.81  148.95  148.96  148.81   \n",
      "2023-01-03 09:05:00   409  148.9411  148.95  148.95  148.95  148.95   \n",
      "\n",
      "                                 t   n   returns  \n",
      "timestamp                                         \n",
      "2023-01-03 09:00:00  1672736400000  87       NaN  \n",
      "2023-01-03 09:02:00  1672736520000  11 -0.006714  \n",
      "2023-01-03 09:03:00  1672736580000  26 -0.060427  \n",
      "2023-01-03 09:04:00  1672736640000  28  0.067182  \n",
      "2023-01-03 09:05:00  1672736700000  13  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Your Polygon API key\n",
    "API_KEY = 'xDoEKdH8gCRADKFy5hDGAq36frjsqge_'\n",
    "\n",
    "def fetch_data(symbol, start_date, end_date):\n",
    "    url = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/minute/{start_date}/{end_date}?apiKey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.DataFrame(response.json()['results'])\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {symbol} on {start_date} to {end_date}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Symbols you're interested in (including an S&P 500 ETF for approximation)\n",
    "symbols = ['NVDA', 'GOOGL', 'AAPL', 'SPY'] # SPY is an ETF that tracks the S&P 500\n",
    "start_date = '2023-01-03'\n",
    "end_date = '2023-01-10'\n",
    "\n",
    "# Fetch and store data for each symbol\n",
    "data_frames = {}\n",
    "for symbol in symbols:\n",
    "    df = fetch_data(symbol, start_date, end_date)\n",
    "    if not df.empty:\n",
    "        # Convert timestamp to readable date and time format\n",
    "        df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        # Calculate minute-by-minute returns\n",
    "        df['returns'] = df['c'].pct_change() * 100 # 'c' is the closing price\n",
    "        data_frames[symbol] = df\n",
    "\n",
    "# Example: Check data for NVDA\n",
    "if 'NVDA' in data_frames:\n",
    "    print(data_frames['NVDA'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5000 entries, 2023-01-03 09:00:00 to 2023-01-10 23:31:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   v        5000 non-null   float64\n",
      " 1   vw       5000 non-null   float64\n",
      " 2   o        5000 non-null   float64\n",
      " 3   c        5000 non-null   float64\n",
      " 4   h        5000 non-null   float64\n",
      " 5   l        5000 non-null   float64\n",
      " 6   t        5000 non-null   int64  \n",
      " 7   n        5000 non-null   int64  \n",
      " 8   returns  4999 non-null   float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 390.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical columns (assuming all columns except 'returns' are features)\n",
    "numerical_cols = ['v', 'vw', 'o', 'c', 'h', 'l', 't', 'n']  # Update if necessary\n",
    "\n",
    "# Create a preprocessing pipeline for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())  # It's good practice to scale features for models like SVM or logistic regression\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'decisiontreeclassifier__max_depth': None, 'decisiontreeclassifier__min_samples_split': 10}\n",
      "Best score: 0.666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       532\n",
      "           1       0.67      0.67      0.67       468\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df[numerical_cols]  # Features\n",
    "y = df['returns'].apply(lambda x: 1 if x > 0 else 0)  # Target variable (1 if stock went up, 0 otherwise)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model pipeline\n",
    "model_pipeline = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [None, 10, 20, 30],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup grid search\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model evaluation\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62f575909710a04b23ad53bfbfcbdffae8e3a88b5ad1048e7da5f6fcba1b84f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 ('cse185')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
